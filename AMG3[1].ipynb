{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b38a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\tjase\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.24.2)\n",
      "Requirement already satisfied: music21 in c:\\users\\tjase\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (9.1.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\tjase\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.14.0)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy music21 tensorflow sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b810b51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair Automatic Music Generation Project\n",
    "#load all the libraries\n",
    "from music21 import *\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.layers import LSTM,Dense,Input,Dropout\n",
    "from tensorflow.keras.models import Sequential,Model,load_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f494652f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "from music21 import converter, instrument, note, chord\n",
    "\n",
    "def read_files(file):\n",
    "    notes = []\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    # Parse the midi file\n",
    "    midi = converter.parse(file)\n",
    "    \n",
    "    # Separate all instruments from the file\n",
    "    instrmt = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    for part in instrmt.parts:\n",
    "        # Fetch data only of Piano instrument\n",
    "        if 'Piano' in str(part):\n",
    "            notes_to_parse = part.recurse()\n",
    "\n",
    "            # Iterate over all the parts of sub stream elements\n",
    "            # Check if element's type is Note or chord\n",
    "            # If it is chord, split them into notes\n",
    "            for element in notes_to_parse:\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    \n",
    "    # Return the list of notes\n",
    "    return notes\n",
    "\n",
    "# Modify the file_path variable to your directory path where MIDI files are stored\n",
    "file_path = r\"C:\\Users\\tjase\\OneDrive\\Desktop\\AUTOMATIC MUSIC PROJECT\\MIDI Files\\bach\"\n",
    "all_files = glob.glob(file_path + '/*.mid', recursive=True)\n",
    "\n",
    "# Reading each midi file\n",
    "notes_list = [read_files(i) for i in tqdm(all_files, position=0, leave=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a525379b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Notes: 114\n",
      "30 : 36\n",
      "50 : 28\n",
      "70 : 18\n",
      "90 : 17\n"
     ]
    }
   ],
   "source": [
    "#unique notes\n",
    "notess = sum(notes_list, [])\n",
    "unique_notes = list(set(notess))\n",
    "print(\"Unique Notes:\", len(unique_notes))\n",
    "\n",
    "#notes with their frequency\n",
    "freq = dict(map(lambda x: (x, notess.count(x)), unique_notes))\n",
    "\n",
    "#get the threshold frequency\n",
    "for i in range(30, 100, 20):\n",
    "    print(i, \":\", len(list(filter(lambda x: x[1] >= i, freq.items()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f03629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter notes greater than threshold i.e., 50\n",
    "freq_notes = dict(filter(lambda x: x[1] >= 50, freq.items()))\n",
    "\n",
    "# Create new notes using the frequent notes\n",
    "new_notes = [[i for i in j if i in freq_notes] for j in notes_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b40c09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary having key as note index and value as note\n",
    "ind2note=dict(enumerate(freq_notes))\n",
    "\n",
    "#dictionary having key as note and value as note index\n",
    "note2ind=dict(map(reversed,ind2note.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b78683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#timestep\n",
    "timesteps=50\n",
    "\n",
    "#store values of input and output\n",
    "x=[] ; y=[]\n",
    "\n",
    "for i in new_notes:\n",
    "  for j in range(0,len(i)-timesteps):\n",
    "    #input will be the current index + timestep\n",
    "    #output will be the next index after timestep\n",
    "    inp=i[j:j+timesteps] ; out=i[j+timesteps]\n",
    "\n",
    "    #append the index value of respective notes \n",
    "    x.append(list(map(lambda x:note2ind[x],inp)))\n",
    "    y.append(note2ind[out])\n",
    "\n",
    "x_new=np.array(x) \n",
    "y_new=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dac89cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape input and output for the model\n",
    "x_new = np.reshape(x_new,(len(x_new),timesteps,1))\n",
    "y_new = np.reshape(y_new,(-1,1))\n",
    "\n",
    "#split the input and value into training and testing sets\n",
    "#80% for training and 20% for testing sets\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_new,y_new,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2b6fc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50, 256)           264192    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50, 256)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 28)                7196      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 862492 (3.29 MB)\n",
      "Trainable params: 862492 (3.29 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create the model\n",
    "model = Sequential()\n",
    "#create two stacked LSTM layer with the latent dimension of 256\n",
    "model.add(LSTM(256,return_sequences=True,input_shape=(x_new.shape[1],x_new.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "\n",
    "#fully connected layer for the output with softmax activation\n",
    "model.add(Dense(len(note2ind),activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21321bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "20/20 [==============================] - 12s 407ms/step - loss: 3.2763 - accuracy: 0.0439 - val_loss: 3.2428 - val_accuracy: 0.0788\n",
      "Epoch 2/80\n",
      "20/20 [==============================] - 10s 525ms/step - loss: 3.2358 - accuracy: 0.0656 - val_loss: 3.2094 - val_accuracy: 0.0772\n",
      "Epoch 3/80\n",
      "20/20 [==============================] - 10s 525ms/step - loss: 3.2111 - accuracy: 0.0781 - val_loss: 3.2174 - val_accuracy: 0.0595\n",
      "Epoch 4/80\n",
      "20/20 [==============================] - 10s 511ms/step - loss: 3.2044 - accuracy: 0.0857 - val_loss: 3.1807 - val_accuracy: 0.0820\n",
      "Epoch 5/80\n",
      "20/20 [==============================] - 11s 529ms/step - loss: 3.1812 - accuracy: 0.0821 - val_loss: 3.1819 - val_accuracy: 0.0772\n",
      "Epoch 6/80\n",
      "20/20 [==============================] - 10s 495ms/step - loss: 3.1691 - accuracy: 0.0861 - val_loss: 3.1658 - val_accuracy: 0.0884\n",
      "Epoch 7/80\n",
      "20/20 [==============================] - 9s 455ms/step - loss: 3.1700 - accuracy: 0.0849 - val_loss: 3.1745 - val_accuracy: 0.0820\n",
      "Epoch 8/80\n",
      "20/20 [==============================] - 9s 467ms/step - loss: 3.1540 - accuracy: 0.0893 - val_loss: 3.1656 - val_accuracy: 0.0884\n",
      "Epoch 9/80\n",
      "20/20 [==============================] - 9s 460ms/step - loss: 3.1455 - accuracy: 0.0918 - val_loss: 3.1686 - val_accuracy: 0.1013\n",
      "Epoch 10/80\n",
      "20/20 [==============================] - 9s 465ms/step - loss: 3.1429 - accuracy: 0.0861 - val_loss: 3.1686 - val_accuracy: 0.0900\n",
      "Epoch 11/80\n",
      "20/20 [==============================] - 9s 464ms/step - loss: 3.1366 - accuracy: 0.0918 - val_loss: 3.1463 - val_accuracy: 0.0981\n",
      "Epoch 12/80\n",
      "20/20 [==============================] - 10s 486ms/step - loss: 3.1278 - accuracy: 0.0950 - val_loss: 3.1537 - val_accuracy: 0.0900\n",
      "Epoch 13/80\n",
      "20/20 [==============================] - 10s 497ms/step - loss: 3.1099 - accuracy: 0.0905 - val_loss: 3.1473 - val_accuracy: 0.0949\n",
      "Epoch 14/80\n",
      "20/20 [==============================] - 10s 477ms/step - loss: 3.1017 - accuracy: 0.0958 - val_loss: 3.1614 - val_accuracy: 0.0852\n",
      "Epoch 15/80\n",
      "20/20 [==============================] - 10s 498ms/step - loss: 3.0887 - accuracy: 0.0934 - val_loss: 3.1437 - val_accuracy: 0.1045\n",
      "Epoch 16/80\n",
      "20/20 [==============================] - 10s 491ms/step - loss: 3.0609 - accuracy: 0.1046 - val_loss: 3.1511 - val_accuracy: 0.0884\n",
      "Epoch 17/80\n",
      "20/20 [==============================] - 10s 517ms/step - loss: 3.0727 - accuracy: 0.1046 - val_loss: 3.1763 - val_accuracy: 0.0916\n",
      "Epoch 18/80\n",
      "20/20 [==============================] - 10s 501ms/step - loss: 3.0413 - accuracy: 0.0982 - val_loss: 3.1610 - val_accuracy: 0.0997\n",
      "Epoch 19/80\n",
      "20/20 [==============================] - 10s 500ms/step - loss: 3.0157 - accuracy: 0.1183 - val_loss: 3.1636 - val_accuracy: 0.0852\n",
      "Epoch 20/80\n",
      "20/20 [==============================] - 10s 492ms/step - loss: 2.9826 - accuracy: 0.1219 - val_loss: 3.2098 - val_accuracy: 0.0949\n",
      "Epoch 21/80\n",
      "20/20 [==============================] - 10s 501ms/step - loss: 2.9854 - accuracy: 0.1123 - val_loss: 3.1823 - val_accuracy: 0.0804\n",
      "Epoch 22/80\n",
      "20/20 [==============================] - 10s 494ms/step - loss: 2.9409 - accuracy: 0.1344 - val_loss: 3.1569 - val_accuracy: 0.0965\n",
      "Epoch 23/80\n",
      "20/20 [==============================] - 10s 500ms/step - loss: 2.8959 - accuracy: 0.1324 - val_loss: 3.1870 - val_accuracy: 0.0997\n",
      "Epoch 24/80\n",
      "20/20 [==============================] - 10s 482ms/step - loss: 2.8763 - accuracy: 0.1441 - val_loss: 3.1498 - val_accuracy: 0.0804\n",
      "Epoch 25/80\n",
      "20/20 [==============================] - 9s 447ms/step - loss: 2.8163 - accuracy: 0.1594 - val_loss: 3.1570 - val_accuracy: 0.0884\n",
      "Epoch 26/80\n",
      "20/20 [==============================] - 9s 442ms/step - loss: 2.7596 - accuracy: 0.1674 - val_loss: 3.1467 - val_accuracy: 0.1061\n",
      "Epoch 27/80\n",
      "20/20 [==============================] - 9s 445ms/step - loss: 2.7140 - accuracy: 0.1795 - val_loss: 3.1738 - val_accuracy: 0.0949\n",
      "Epoch 28/80\n",
      "20/20 [==============================] - 9s 447ms/step - loss: 2.6256 - accuracy: 0.2040 - val_loss: 3.1576 - val_accuracy: 0.0965\n",
      "Epoch 29/80\n",
      "20/20 [==============================] - 9s 443ms/step - loss: 2.5578 - accuracy: 0.2354 - val_loss: 3.1873 - val_accuracy: 0.1029\n",
      "Epoch 30/80\n",
      "20/20 [==============================] - 9s 441ms/step - loss: 2.4998 - accuracy: 0.2350 - val_loss: 3.1663 - val_accuracy: 0.1061\n",
      "Epoch 31/80\n",
      "20/20 [==============================] - 9s 456ms/step - loss: 2.4159 - accuracy: 0.2563 - val_loss: 3.2107 - val_accuracy: 0.1109\n",
      "Epoch 32/80\n",
      "20/20 [==============================] - 9s 442ms/step - loss: 2.3181 - accuracy: 0.2813 - val_loss: 3.2575 - val_accuracy: 0.1061\n",
      "Epoch 33/80\n",
      "20/20 [==============================] - 9s 438ms/step - loss: 2.2223 - accuracy: 0.3167 - val_loss: 3.2787 - val_accuracy: 0.1013\n",
      "Epoch 34/80\n",
      "20/20 [==============================] - 9s 444ms/step - loss: 2.1398 - accuracy: 0.3433 - val_loss: 3.3190 - val_accuracy: 0.1077\n",
      "Epoch 35/80\n",
      "20/20 [==============================] - 9s 439ms/step - loss: 2.0203 - accuracy: 0.3586 - val_loss: 3.3405 - val_accuracy: 0.1238\n",
      "Epoch 36/80\n",
      "20/20 [==============================] - 9s 440ms/step - loss: 1.8866 - accuracy: 0.4020 - val_loss: 3.4154 - val_accuracy: 0.1013\n",
      "Epoch 37/80\n",
      "20/20 [==============================] - 9s 443ms/step - loss: 1.7877 - accuracy: 0.4414 - val_loss: 3.4772 - val_accuracy: 0.1158\n",
      "Epoch 38/80\n",
      "20/20 [==============================] - 9s 440ms/step - loss: 1.6764 - accuracy: 0.4672 - val_loss: 3.5382 - val_accuracy: 0.1206\n",
      "Epoch 39/80\n",
      "20/20 [==============================] - 9s 441ms/step - loss: 1.5902 - accuracy: 0.4986 - val_loss: 3.5734 - val_accuracy: 0.1318\n",
      "Epoch 40/80\n",
      "20/20 [==============================] - 9s 441ms/step - loss: 1.5187 - accuracy: 0.5296 - val_loss: 3.6316 - val_accuracy: 0.1270\n",
      "Epoch 41/80\n",
      "20/20 [==============================] - 9s 443ms/step - loss: 1.3516 - accuracy: 0.5771 - val_loss: 3.7807 - val_accuracy: 0.1158\n",
      "Epoch 42/80\n",
      "20/20 [==============================] - 9s 442ms/step - loss: 1.2479 - accuracy: 0.5980 - val_loss: 3.8579 - val_accuracy: 0.1270\n",
      "Epoch 43/80\n",
      "20/20 [==============================] - 9s 444ms/step - loss: 1.1437 - accuracy: 0.6435 - val_loss: 4.0027 - val_accuracy: 0.1174\n",
      "Epoch 44/80\n",
      "20/20 [==============================] - 9s 445ms/step - loss: 1.0769 - accuracy: 0.6624 - val_loss: 4.0302 - val_accuracy: 0.1141\n",
      "Epoch 45/80\n",
      "20/20 [==============================] - 9s 450ms/step - loss: 0.9671 - accuracy: 0.7115 - val_loss: 4.1148 - val_accuracy: 0.1222\n",
      "Epoch 46/80\n",
      "20/20 [==============================] - 9s 442ms/step - loss: 0.8694 - accuracy: 0.7525 - val_loss: 4.2391 - val_accuracy: 0.1125\n",
      "Epoch 47/80\n",
      "20/20 [==============================] - 9s 438ms/step - loss: 0.8086 - accuracy: 0.7557 - val_loss: 4.2927 - val_accuracy: 0.1158\n",
      "Epoch 48/80\n",
      "20/20 [==============================] - 9s 446ms/step - loss: 0.7278 - accuracy: 0.7903 - val_loss: 4.4446 - val_accuracy: 0.1222\n",
      "Epoch 49/80\n",
      "20/20 [==============================] - 9s 442ms/step - loss: 0.6760 - accuracy: 0.7976 - val_loss: 4.5254 - val_accuracy: 0.1125\n",
      "Epoch 50/80\n",
      "20/20 [==============================] - 9s 440ms/step - loss: 0.5820 - accuracy: 0.8394 - val_loss: 4.6307 - val_accuracy: 0.1061\n",
      "Epoch 51/80\n",
      "20/20 [==============================] - 9s 462ms/step - loss: 0.5363 - accuracy: 0.8547 - val_loss: 4.7650 - val_accuracy: 0.1125\n",
      "Epoch 52/80\n",
      "20/20 [==============================] - 10s 493ms/step - loss: 0.4761 - accuracy: 0.8765 - val_loss: 4.8729 - val_accuracy: 0.1125\n",
      "Epoch 53/80\n",
      "20/20 [==============================] - 11s 538ms/step - loss: 0.4392 - accuracy: 0.8813 - val_loss: 4.9845 - val_accuracy: 0.1190\n",
      "Epoch 54/80\n",
      "20/20 [==============================] - 11s 530ms/step - loss: 0.4549 - accuracy: 0.8817 - val_loss: 4.9679 - val_accuracy: 0.1109\n",
      "Epoch 55/80\n",
      "20/20 [==============================] - 11s 555ms/step - loss: 0.3864 - accuracy: 0.9022 - val_loss: 5.0528 - val_accuracy: 0.1125\n",
      "Epoch 56/80\n",
      "20/20 [==============================] - 11s 545ms/step - loss: 0.3579 - accuracy: 0.9034 - val_loss: 5.2021 - val_accuracy: 0.1141\n",
      "Epoch 57/80\n",
      "20/20 [==============================] - 14s 706ms/step - loss: 0.2978 - accuracy: 0.9324 - val_loss: 5.2208 - val_accuracy: 0.1141\n",
      "Epoch 58/80\n",
      "20/20 [==============================] - 12s 577ms/step - loss: 0.2736 - accuracy: 0.9348 - val_loss: 5.3933 - val_accuracy: 0.1174\n",
      "Epoch 59/80\n",
      "20/20 [==============================] - 10s 493ms/step - loss: 0.2497 - accuracy: 0.9445 - val_loss: 5.4539 - val_accuracy: 0.1190\n",
      "Epoch 60/80\n",
      "20/20 [==============================] - 9s 449ms/step - loss: 0.2371 - accuracy: 0.9477 - val_loss: 5.4600 - val_accuracy: 0.1158\n",
      "Epoch 61/80\n",
      "20/20 [==============================] - 10s 510ms/step - loss: 0.2101 - accuracy: 0.9561 - val_loss: 5.6093 - val_accuracy: 0.1077\n",
      "Epoch 62/80\n",
      "20/20 [==============================] - 11s 553ms/step - loss: 0.2028 - accuracy: 0.9557 - val_loss: 5.6896 - val_accuracy: 0.1109\n",
      "Epoch 63/80\n",
      "20/20 [==============================] - 12s 588ms/step - loss: 0.1957 - accuracy: 0.9549 - val_loss: 5.6823 - val_accuracy: 0.1238\n",
      "Epoch 64/80\n",
      "20/20 [==============================] - 13s 635ms/step - loss: 0.1915 - accuracy: 0.9565 - val_loss: 5.7369 - val_accuracy: 0.1174\n",
      "Epoch 65/80\n",
      "20/20 [==============================] - 14s 704ms/step - loss: 0.1587 - accuracy: 0.9638 - val_loss: 5.8882 - val_accuracy: 0.1158\n",
      "Epoch 66/80\n",
      "20/20 [==============================] - 16s 804ms/step - loss: 0.1614 - accuracy: 0.9626 - val_loss: 5.8820 - val_accuracy: 0.1141\n",
      "Epoch 67/80\n",
      "20/20 [==============================] - 16s 797ms/step - loss: 0.1465 - accuracy: 0.9654 - val_loss: 5.9919 - val_accuracy: 0.1045\n",
      "Epoch 68/80\n",
      "20/20 [==============================] - 13s 644ms/step - loss: 0.1325 - accuracy: 0.9722 - val_loss: 6.1009 - val_accuracy: 0.1109\n",
      "Epoch 69/80\n",
      "20/20 [==============================] - 11s 560ms/step - loss: 0.1326 - accuracy: 0.9726 - val_loss: 6.0858 - val_accuracy: 0.1174\n",
      "Epoch 70/80\n",
      "20/20 [==============================] - 14s 704ms/step - loss: 0.1245 - accuracy: 0.9763 - val_loss: 6.1749 - val_accuracy: 0.1109\n",
      "Epoch 71/80\n",
      "20/20 [==============================] - 14s 716ms/step - loss: 0.1177 - accuracy: 0.9751 - val_loss: 6.2473 - val_accuracy: 0.1141\n",
      "Epoch 72/80\n",
      "20/20 [==============================] - 17s 850ms/step - loss: 0.1118 - accuracy: 0.9787 - val_loss: 6.2345 - val_accuracy: 0.1190\n",
      "Epoch 73/80\n",
      "20/20 [==============================] - 20s 1s/step - loss: 0.1048 - accuracy: 0.9767 - val_loss: 6.3558 - val_accuracy: 0.1061\n",
      "Epoch 74/80\n",
      "20/20 [==============================] - 21s 1s/step - loss: 0.1030 - accuracy: 0.9779 - val_loss: 6.3049 - val_accuracy: 0.1125\n",
      "Epoch 75/80\n",
      "20/20 [==============================] - 19s 932ms/step - loss: 0.0900 - accuracy: 0.9855 - val_loss: 6.3584 - val_accuracy: 0.1222\n",
      "Epoch 76/80\n",
      "20/20 [==============================] - 16s 780ms/step - loss: 0.0948 - accuracy: 0.9815 - val_loss: 6.3982 - val_accuracy: 0.1141\n",
      "Epoch 77/80\n",
      "20/20 [==============================] - 13s 641ms/step - loss: 0.0931 - accuracy: 0.9795 - val_loss: 6.4399 - val_accuracy: 0.1158\n",
      "Epoch 78/80\n",
      "20/20 [==============================] - 13s 672ms/step - loss: 0.0925 - accuracy: 0.9791 - val_loss: 6.5175 - val_accuracy: 0.1077\n",
      "Epoch 79/80\n",
      "20/20 [==============================] - 14s 715ms/step - loss: 0.0971 - accuracy: 0.9803 - val_loss: 6.4654 - val_accuracy: 0.1141\n",
      "Epoch 80/80\n",
      "20/20 [==============================] - 16s 818ms/step - loss: 0.0894 - accuracy: 0.9823 - val_loss: 6.5733 - val_accuracy: 0.1190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d8e09d51d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#compile the model using Adam optimizer\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#train the model on training sets and validate on testing sets\n",
    "model.fit(\n",
    "    x_train,y_train,\n",
    "    batch_size=128,epochs=80, \n",
    "    validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d54325ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tjase\\OneDrive\\Desktop\\AUTOMATIC MUSIC PROJECT\\new prediction\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tjase\\OneDrive\\Desktop\\AUTOMATIC MUSIC PROJECT\\new prediction\\assets\n"
     ]
    }
   ],
   "source": [
    "#save the model for predictions\n",
    "model.save(r\"C:\\Users\\tjase\\OneDrive\\Desktop\\AUTOMATIC MUSIC PROJECT\\new prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38c7ecc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 995ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = load_model(r\"C:\\Users\\tjase\\OneDrive\\Desktop\\AUTOMATIC MUSIC PROJECT\\new prediction\")\n",
    "# generate random index\n",
    "index = np.random.randint(0, len(x_test) - 1)\n",
    "# get the data of generated index from x_test\n",
    "music_pattern = x_test[index]\n",
    "out_pred = []  # it will store predicted notes\n",
    "\n",
    "# iterate till 200 note is generated\n",
    "for i in range(200):\n",
    "    # reshape the music pattern\n",
    "    music_pattern = music_pattern.reshape(1, len(music_pattern), 1)\n",
    "\n",
    "    # get the maximum probability value from the predicted output\n",
    "    pred_index = np.argmax(model.predict(music_pattern))\n",
    "    # get the note using predicted index and\n",
    "    # append to the output prediction list\n",
    "    out_pred.append(ind2note[pred_index])\n",
    "    music_pattern = np.append(music_pattern, pred_index)\n",
    "\n",
    "    # update the music pattern with one timestep ahead\n",
    "    music_pattern = music_pattern[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87e85294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new2.mid'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from music21 import note, chord, instrument, stream\n",
    "\n",
    "output_notes = []\n",
    "\n",
    "for offset, pattern in enumerate(out_pred):\n",
    "    # if pattern is a chord instance\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        # split notes from the chord\n",
    "        notes_in_chord = pattern.split('.')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            i_curr_note = int(current_note)\n",
    "            # cast the current note to Note object and\n",
    "            # append the current note\n",
    "            new_note = note.Note(i_curr_note)\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            notes.append(new_note)\n",
    "\n",
    "        # cast the current note to Chord object\n",
    "        # offset will be 1 step ahead from the previous note\n",
    "        # as it will prevent notes to stack up\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "\n",
    "    else:\n",
    "        # cast the pattern to Note object, apply the offset, and\n",
    "        # append the note\n",
    "        new_note = note.Note(pattern)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "\n",
    "# Save the midi file with the name 'hafiz.mid'\n",
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write('midi',fp='new2.mid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3647daab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/tjase/OneDrive/Desktop/new2.mid')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the midi file with the name 'hafiz.mid'\n",
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write(fp='new2.mid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d697a7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
